{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deeppavlov_testing.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hwt8dV7wVlww",
        "outputId": "fab99313-0ccf-4d64-a165-dca699c295e9"
      },
      "source": [
        "! pip install deeppavlov"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting deeppavlov\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d3/08/b0e17b109873563a78c9c06437db1bcc698592f86b5aebe5038004b5969e/deeppavlov-0.14.0-py3-none-any.whl (988kB)\n",
            "\r\u001b[K     |▎                               | 10kB 15.8MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 16.7MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 9.7MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 8.0MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 8.4MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.4MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 9.0MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 8.3MB/s eta 0:00:01\r\u001b[K     |███                             | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▎                            | 102kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▋                            | 112kB 8.4MB/s eta 0:00:01\r\u001b[K     |████                            | 122kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▎                           | 133kB 8.4MB/s eta 0:00:01\r\u001b[K     |████▋                           | 143kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 153kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 163kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 174kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████                          | 184kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 194kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 204kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 215kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 225kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 235kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 245kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 256kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 266kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████                       | 276kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 286kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 296kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████                      | 307kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 317kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 327kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████                     | 337kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 348kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 358kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████                    | 368kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 378kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 389kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 399kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 409kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 419kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 430kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 440kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 450kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 460kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 471kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 481kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████                | 491kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 501kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 512kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 522kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 532kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 542kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 552kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 563kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 573kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 583kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 593kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 604kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 614kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 624kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 634kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 645kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 655kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 665kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 675kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 686kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 696kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 706kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 716kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 727kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 737kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 747kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 757kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 768kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 778kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 788kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 798kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 808kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 819kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 829kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 839kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 849kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 860kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 870kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 880kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 890kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 901kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 911kB 8.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 921kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 931kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 942kB 8.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 952kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 962kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 972kB 8.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 983kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 993kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (1.4.1)\n",
            "Collecting prometheus-client==0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b3/23/41a5a24b502d35a4ad50a5bb7202a5e1d9a0364d0c12f56db3dbf7aca76d/prometheus_client-0.7.1.tar.gz\n",
            "Collecting pymorphy2-dicts-ru\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 14.7MB/s \n",
            "\u001b[?25hCollecting Cython==0.29.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/58/2deb24de3c10cc4c0f09639b46f4f4b50059f0fdc785128a57dd9fdce026/Cython-0.29.14-cp37-cp37m-manylinux1_x86_64.whl (2.1MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1MB 28.6MB/s \n",
            "\u001b[?25hCollecting ruamel.yaml==0.15.100\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/fc/12de89822adaa3a60b8cb0139bae75918278999d08e6dff158623abd7cba/ruamel.yaml-0.15.100-cp37-cp37m-manylinux1_x86_64.whl (654kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 36.7MB/s \n",
            "\u001b[?25hCollecting pytelegrambotapi==3.6.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/ab/99c606f69fcda57e35788b913dd34c9d9acb48dd26349141b3855dcf6351/pyTelegramBotAPI-3.6.7.tar.gz (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.5MB/s \n",
            "\u001b[?25hCollecting pandas==0.25.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/63/e0/a1b39cdcb2c391f087a1538bc8a6d62a82d0439693192aef541d7b123769/pandas-0.25.3-cp37-cp37m-manylinux1_x86_64.whl (10.4MB)\n",
            "\u001b[K     |████████████████████████████████| 10.4MB 33.7MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.21.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/a4/a48bd4b0d15395362b561df7e7247de87291105eb736a3b2aaffebf437b9/scikit_learn-0.21.2-cp37-cp37m-manylinux1_x86_64.whl (6.7MB)\n",
            "\u001b[K     |████████████████████████████████| 6.7MB 31.6MB/s \n",
            "\u001b[?25hCollecting pydantic==1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4b/56/1f652c3f658d2a9fd495d2e988a2da57eabdb6c4b8f4563c2ccbe6a2a8c5/pydantic-1.3-cp37-cp37m-manylinux2010_x86_64.whl (7.3MB)\n",
            "\u001b[K     |████████████████████████████████| 7.3MB 18.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (7.1.2)\n",
            "Requirement already satisfied: h5py==2.10.0 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (2.10.0)\n",
            "Collecting pytz==2019.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3d/73/fe30c2daaaa0713420d0382b16fbb761409f532c56bdcc514bf7b6262bb6/pytz-2019.1-py2.py3-none-any.whl (510kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 42.6MB/s \n",
            "\u001b[?25hCollecting aio-pika==6.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/07/196a4115cbef31fa0c3dabdea146f02dffe5e49998341d20dbe2278953bc/aio_pika-6.4.1-py3-none-any.whl (40kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 5.9MB/s \n",
            "\u001b[?25hCollecting uvicorn==0.11.7\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/5f/2bc87272f189662e129ddcd4807ad3ef83128b4df3a3482335f5f9790f24/uvicorn-0.11.7-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm==4.41.1 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (4.41.1)\n",
            "Collecting nltk==3.4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 31.1MB/s \n",
            "\u001b[?25hCollecting pyopenssl==19.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/de/f8342b68fa9e981d348039954657bdf681b2ab93de27443be51865ffa310/pyOpenSSL-19.1.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.7MB/s \n",
            "\u001b[?25hCollecting overrides==2.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ac/98/2430afd204c48ac0a529d439d7e22df8fa603c668d03456b5947cb59ec36/overrides-2.7.0.tar.gz\n",
            "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from deeppavlov) (3.0.12)\n",
            "Collecting pymorphy2==0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/33/fff9675c68b5f6c63ec8c6e6ff57827dda28a1fa5b2c2d727dffff92dd47/pymorphy2-0.8-py2.py3-none-any.whl (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting rusenttokenize==0.0.5\n",
            "  Downloading https://files.pythonhosted.org/packages/25/4c/a2f00be5def774a3df2e5387145f1cb54e324607ec4a7e23f573645946e7/rusenttokenize-0.0.5-py3-none-any.whl\n",
            "Collecting requests==2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.9MB/s \n",
            "\u001b[?25hCollecting fastapi==0.47.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/a7/4804d7abf8a1544d079d50650af872387154ebdac5bd07d54b2e60e2b334/fastapi-0.47.1-py3-none-any.whl (43kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/53/127cb49435bcf5d841baf8eafa030931c62a9eac577a641f8c2293d23371/numpy-1.18.0-cp37-cp37m-manylinux1_x86_64.whl (20.1MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1MB 95kB/s \n",
            "\u001b[?25hCollecting sacremoses==0.0.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1f/8e/ed5364a06a9ba720fddd9820155cc57300d28f5f43a6fd7b7e817177e642/sacremoses-0.0.35.tar.gz (859kB)\n",
            "\u001b[K     |████████████████████████████████| 860kB 37.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytelegrambotapi==3.6.7->deeppavlov) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from pandas==0.25.3->deeppavlov) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.21.2->deeppavlov) (1.0.1)\n",
            "Collecting aiormq<4,>=3.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/0b/c4/dc5b9d50c15af2ee187974a5a0c3f20c06cce6559eea4c065d372e846b6a/aiormq-3.3.1-py3-none-any.whl\n",
            "Collecting yarl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f1/62/046834c5fc998c88ab2ef722f5d42122230a632212c8afa76418324f53ff/yarl-1.6.3-cp37-cp37m-manylinux2014_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 41.7MB/s \n",
            "\u001b[?25hCollecting websockets==8.*\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/0b/3ebc752392a368af14dd24ee041683416ac6d2463eead94b311b11e41c82/websockets-8.1-cp37-cp37m-manylinux2010_x86_64.whl (79kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.4MB/s \n",
            "\u001b[?25hCollecting httptools==0.1.*; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/52/295101ea5a60f9bee805a3ca422863600ba5cac4e2778ac7bd56efab1231/httptools-0.1.1-cp37-cp37m-manylinux1_x86_64.whl (217kB)\n",
            "\u001b[K     |████████████████████████████████| 225kB 42.5MB/s \n",
            "\u001b[?25hCollecting h11<0.10,>=0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/fd/3dad730b0f95e78aeeb742f96fa7bbecbdd56a58e405d3da440d5bfb90c6/h11-0.9.0-py2.py3-none-any.whl (53kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.1MB/s \n",
            "\u001b[?25hCollecting uvloop>=0.14.0; sys_platform != \"win32\" and sys_platform != \"cygwin\" and platform_python_implementation != \"PyPy\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/05/805df4850d9659efd69d00076269ae6adcb0e151d1922cff822ead2c432a/uvloop-0.15.2-cp37-cp37m-manylinux2010_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 34.3MB/s \n",
            "\u001b[?25hCollecting cryptography>=2.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/1f/acde6ff69864c5e78b56488e3afd93c1ccc8c2651186e2a5f93d93f64859/cryptography-3.4.6-cp36-abi3-manylinux2014_x86_64.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 40.0MB/s \n",
            "\u001b[?25hCollecting pymorphy2-dicts<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/51/2465fd4f72328ab50877b54777764d928da8cb15b74e2680fc1bd8cb3173/pymorphy2_dicts-2.4.393442.3710985-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 17.2MB/s \n",
            "\u001b[?25hCollecting dawg-python>=0.7\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2==0.8->deeppavlov) (0.6.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (1.24.3)\n",
            "Collecting idna<2.9,>=2.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.22.0->deeppavlov) (2020.12.5)\n",
            "Collecting starlette<=0.12.9,>=0.12.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/67/95/2220fe5bf287e693a6430d8ee36c681b0157035b7249ec08f8fb36319d16/starlette-0.12.9.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.0MB/s \n",
            "\u001b[?25hCollecting pamqp==2.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/eb/56/afa06143361e640c9159d828dadc95fc9195c52c95b4a97d136617b0166d/pamqp-2.3.0-py2.py3-none-any.whl\n",
            "Collecting multidict>=4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a6/4123b8165acbe773d1a8dc8e3f0d1edea16d29f7de018eda769abb56bd30/multidict-5.1.0-cp37-cp37m-manylinux2014_x86_64.whl (142kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 39.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from yarl->aio-pika==6.4.1->deeppavlov) (3.7.4.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (1.14.5)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.8->pyopenssl==19.1.0->deeppavlov) (2.20)\n",
            "Building wheels for collected packages: prometheus-client, pytelegrambotapi, nltk, overrides, sacremoses, starlette\n",
            "  Building wheel for prometheus-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-client: filename=prometheus_client-0.7.1-cp37-none-any.whl size=41404 sha256=b9cc288a7677cdc0751a63619aa566db9871c979216fa99b92207cb4968c1cb9\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/54/34/fd47cd9b308826cc4292b54449c1899a30251ef3b506bc91ea\n",
            "  Building wheel for pytelegrambotapi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytelegrambotapi: filename=pyTelegramBotAPI-3.6.7-cp37-none-any.whl size=47177 sha256=457bb887d1ea590b864926695df983678ff1c78a574e1c14df7a7d04ad0310d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/40/18/8a34153f95ef0dc19e3954898e5a5079244b76a8afdd7d0ec5\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp37-none-any.whl size=1449905 sha256=e1f1c47703131d406a738600aa78a78c4c72f4b423e2189ee4ede72e3c61f361\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-2.7.0-cp37-none-any.whl size=5600 sha256=2ad0d3442279adf7532766ad7bc00d1cfc406f3741208c1c9d6d89a9360ddb42\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/7c/ef/80508418b67d87371c5b3de49e03eb22ee7c1d19affb5099f8\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.35-cp37-none-any.whl size=883999 sha256=9be2a0f98198ee99e143ab8dea09c0d1cc12e6d54fb5e131a8d4071dc31d4a86\n",
            "  Stored in directory: /root/.cache/pip/wheels/63/2a/db/63e2909042c634ef551d0d9ac825b2b0b32dede4a6d87ddc94\n",
            "  Building wheel for starlette (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for starlette: filename=starlette-0.12.9-cp37-none-any.whl size=57244 sha256=bbefb740b7e32b32a8a386daa2af64c3f41ac22822a99f76289710456a465442\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/51/5b/3828d52e185cafad941c4291b6f70894d0794be28c70addae5\n",
            "Successfully built prometheus-client pytelegrambotapi nltk overrides sacremoses starlette\n",
            "\u001b[31mERROR: umap-learn 0.5.1 has requirement scikit-learn>=0.22, but you'll have scikit-learn 0.21.2 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow 2.4.1 has requirement numpy~=1.19.2, but you'll have numpy 1.18.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.1.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.22.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: fbprophet 0.7.1 has requirement pandas>=1.0.4, but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: prometheus-client, pymorphy2-dicts-ru, Cython, ruamel.yaml, idna, requests, pytelegrambotapi, pytz, numpy, pandas, scikit-learn, pydantic, pamqp, multidict, yarl, aiormq, aio-pika, websockets, httptools, h11, uvloop, uvicorn, nltk, cryptography, pyopenssl, overrides, pymorphy2-dicts, dawg-python, pymorphy2, rusenttokenize, starlette, fastapi, sacremoses, deeppavlov\n",
            "  Found existing installation: prometheus-client 0.9.0\n",
            "    Uninstalling prometheus-client-0.9.0:\n",
            "      Successfully uninstalled prometheus-client-0.9.0\n",
            "  Found existing installation: Cython 0.29.22\n",
            "    Uninstalling Cython-0.29.22:\n",
            "      Successfully uninstalled Cython-0.29.22\n",
            "  Found existing installation: idna 2.10\n",
            "    Uninstalling idna-2.10:\n",
            "      Successfully uninstalled idna-2.10\n",
            "  Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Found existing installation: pytz 2018.9\n",
            "    Uninstalling pytz-2018.9:\n",
            "      Successfully uninstalled pytz-2018.9\n",
            "  Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Found existing installation: pandas 1.1.5\n",
            "    Uninstalling pandas-1.1.5:\n",
            "      Successfully uninstalled pandas-1.1.5\n",
            "  Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "Successfully installed Cython-0.29.14 aio-pika-6.4.1 aiormq-3.3.1 cryptography-3.4.6 dawg-python-0.7.2 deeppavlov-0.14.0 fastapi-0.47.1 h11-0.9.0 httptools-0.1.1 idna-2.8 multidict-5.1.0 nltk-3.4.5 numpy-1.18.0 overrides-2.7.0 pamqp-2.3.0 pandas-0.25.3 prometheus-client-0.7.1 pydantic-1.3 pymorphy2-0.8 pymorphy2-dicts-2.4.393442.3710985 pymorphy2-dicts-ru-2.4.417127.4579844 pyopenssl-19.1.0 pytelegrambotapi-3.6.7 pytz-2019.1 requests-2.22.0 ruamel.yaml-0.15.100 rusenttokenize-0.0.5 sacremoses-0.0.35 scikit-learn-0.21.2 starlette-0.12.9 uvicorn-0.11.7 uvloop-0.15.2 websockets-8.1 yarl-1.6.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "pandas",
                  "pytz"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pp4Z23P6WgMj",
        "outputId": "4411a6cd-b352-4b36-ddfd-ef03729ae652"
      },
      "source": [
        "from deeppavlov import build_model, configs\n",
        "\n",
        "faq = build_model(configs.faq.tfidf_logreg_en_faq, download=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 09:53:14.406 INFO in 'deeppavlov.core.data.utils'['utils'] at line 94: Downloading from http://files.deeppavlov.ai/faq/mipt/en_mipt_faq_v4.tar.gz to /root/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz\n",
            "100%|██████████| 12.3k/12.3k [00:00<00:00, 6.56MB/s]\n",
            "2021-03-22 09:53:14.710 INFO in 'deeppavlov.core.data.utils'['utils'] at line 268: Extracting /root/.deeppavlov/models/faq/en_mipt_faq_v4.tar.gz archive into /root/.deeppavlov/models/faq/mipt\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "2021-03-22 09:53:20.126 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 09:53:20.128 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2021-03-22 09:53:20.128 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 09:53:20.135 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 09:53:20.137 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 09:53:20.139 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2021-03-22 09:53:20.141 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "06M5TxFPWrcC"
      },
      "source": [
        "from deeppavlov import configs, train_model\n",
        "from deeppavlov.core.common.file import read_json\n",
        "model_config = read_json(configs.faq.tfidf_logreg_en_faq)\n",
        "model_config['dataset_reader']['data_path'] = 'wiki_train.csv'\n",
        "model_config['dataset_reader']['data_url'] = None"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJCj5e3LYGyc"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMnf5_2LYL8k"
      },
      "source": [
        "df = pd.read_csv('WikiQA-train.tsv', sep='\\t')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "rGuHZm0JYtzk",
        "outputId": "20c02b0f-6982-4da0-e87a-bc537924ce92"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>QuestionID</th>\n",
              "      <th>Question</th>\n",
              "      <th>DocumentID</th>\n",
              "      <th>DocumentTitle</th>\n",
              "      <th>SentenceID</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-0</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-1</td>\n",
              "      <td>The ice facade is approximately 60 m high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-2</td>\n",
              "      <td>Ice formations in the Titlis glacier cave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-3</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q1</td>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>D1</td>\n",
              "      <td>Glacier cave</td>\n",
              "      <td>D1-4</td>\n",
              "      <td>Glacier caves are often called ice caves , but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  QuestionID  ... Label\n",
              "0         Q1  ...     0\n",
              "1         Q1  ...     0\n",
              "2         Q1  ...     0\n",
              "3         Q1  ...     1\n",
              "4         Q1  ...     0\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "ySf1xirBYa96",
        "outputId": "a6549230-f2b2-4d09-ebae-21c166229450"
      },
      "source": [
        "df = df[['Question', 'Sentence', 'Label']]\n",
        "df.columns = ['Question', 'Answer', 'Label']\n",
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Question</th>\n",
              "      <th>Answer</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>A partly submerged glacier cave on Perito More...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>The ice facade is approximately 60 m high</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Ice formations in the Titlis glacier cave</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>A glacier cave is a cave formed within the ice...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>how are glacier caves formed?</td>\n",
              "      <td>Glacier caves are often called ice caves , but...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Question  ... Label\n",
              "0  how are glacier caves formed?  ...     0\n",
              "1  how are glacier caves formed?  ...     0\n",
              "2  how are glacier caves formed?  ...     0\n",
              "3  how are glacier caves formed?  ...     1\n",
              "4  how are glacier caves formed?  ...     0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YI43_JZc2jM",
        "outputId": "e763d8ac-6747-414c-808f-af270ddf324e"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20347, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEeQj-BibqjH"
      },
      "source": [
        "df = df[df['Label'] == 1]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXd38ionZ7Pq"
      },
      "source": [
        "df.to_csv('wiki_train.csv')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Getqm5QiX9Ip",
        "outputId": "17496b3c-4756-46b8-b12f-ad72e59451b4"
      },
      "source": [
        "faq_wiki = train_model(model_config)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package perluniprops to /root/nltk_data...\n",
            "[nltk_data]   Package perluniprops is already up-to-date!\n",
            "[nltk_data] Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package nonbreaking_prefixes is already up-to-date!\n",
            "2021-03-22 10:22:36.227 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 10:22:36.230 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2021-03-22 10:22:36.231 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:22:36.855 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.feature_extraction.textTfidfVectorizer\n",
            "2021-03-22 10:22:36.871 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 10:22:36.881 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 10:22:36.956 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 101: [saving vocabulary to /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 10:22:36.963 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 10:22:36.964 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2021-03-22 10:22:36.966 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:22:37.407 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 109: Fitting model sklearn.linear_model.logisticLogisticRegression\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
            "  \"this warning.\", FutureWarning)\n",
            "2021-03-22 10:22:39.886 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 10:22:40.481 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 10:22:40.484 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2021-03-22 10:22:40.487 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:22:40.490 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 10:22:40.499 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 10:22:40.513 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2021-03-22 10:22:40.514 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:22:41.26 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 10:22:41.30 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2021-03-22 10:22:41.32 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:22:41.35 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 10:22:41.43 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 10:22:41.56 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2021-03-22 10:22:41.57 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "qaCbducwdXXv",
        "outputId": "0a92bc99-e3b4-40a5-e8ec-9fd2e4b7e2e3"
      },
      "source": [
        "faq_wiki(['1945'])[0][0]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Cellular respiration is the set of the metabolic reactions and processes that take place in the cells of organisms to convert biochemical energy from nutrients into adenosine triphosphate (ATP), and then release waste products.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B4truyzeDc9",
        "outputId": "eabd3bdd-98d6-481f-fd1c-a499acd8edd9"
      },
      "source": [
        "faq_wiki.save()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 10:25:59.949 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 241: Saving model to /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8A7k3-fkeFwj",
        "outputId": "e986471c-ed4a-4bd5-b6f3-96a4ddf11845"
      },
      "source": [
        "from deeppavlov import build_model\n",
        "\n",
        "new_model = build_model(model_config)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-03-22 10:26:35.717 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.feature_extraction.text:TfidfVectorizer from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/tfidf.pkl\n",
            "2021-03-22 10:26:35.721 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.feature_extraction.textTfidfVectorizer loaded  with parameters\n",
            "2021-03-22 10:26:35.723 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n",
            "2021-03-22 10:26:35.726 INFO in 'deeppavlov.core.data.simple_vocab'['simple_vocab'] at line 115: [loading vocabulary from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/en_mipt_answers.dict]\n",
            "2021-03-22 10:26:35.735 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 203: Loading model sklearn.linear_model:LogisticRegression from /root/.deeppavlov/models/faq/mipt/en_mipt_faq_v4/logreg.pkl\n",
            "2021-03-22 10:26:35.751 INFO in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 210: Model sklearn.linear_model.logisticLogisticRegression loaded  with parameters\n",
            "2021-03-22 10:26:35.752 WARNING in 'deeppavlov.models.sklearn.sklearn_component'['sklearn_component'] at line 216: Fitting of loaded model can not be continued. Model can be fitted from scratch.If one needs to continue fitting, please, look at `warm_start` parameter\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-LqeRwg9e1pb"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('model_config.json', 'w') as outfile:\n",
        "    json.dump(model_config, outfile)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZV7PlrGd_c9"
      },
      "source": [
        "def inference(model, query):\n",
        "    answer = model([query])[0][0]\n",
        "    if answer != 'Cellular respiration is the set of the metabolic reactions and processes that take place in the cells of organisms to convert biochemical energy from nutrients into adenosine triphosphate (ATP), and then release waste products.':\n",
        "        return answer\n",
        "    else:\n",
        "        return 'Sorry, cannot answer your question. Please, ask again.' "
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "rd-Knw_FfcTL",
        "outputId": "91f6481e-4629-4f41-cc03-ae19cc12c334"
      },
      "source": [
        "inference(new_model, 'how are glacier caves formed?')"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "A glacier cave is a cave formed within the ice of a glacier .\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A glacier cave is a cave formed within the ice of a glacier .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H3T6VTytaEN7"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\""
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrBbvVOaf_rx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}